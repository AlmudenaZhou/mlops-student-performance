{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this model is to be able to predict the GradeClass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Student_performance_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I will split the data in 3: training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['GPA', 'GradeClass'], axis=1)\n",
    "y = data[['GradeClass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test, y_val_test, test_size=0.5, random_state=42, stratify=y_val_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes about the columns:\n",
    "\n",
    "- The StudentID will be removed to avoid biases in the grade calculation.\n",
    "- Age, Gender and Ethnicity will be dropped to avoid bias, but this must be consider in the posterior evaluation and to comply with the Responsible AI.\n",
    "\n",
    "- StudyTimeWeekly and Absences need to be scaled. I will check if they are normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra considerations:\n",
    "\n",
    "- For the preprocessing, I will expect a dictionary with all the columns presented in the original dataframe, even though several of them will be dropped.\n",
    "- Non missing values are expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions for the features :\n",
    "\n",
    "- ParentalEducation and ParentalSupport are ordinal categorical variables and will be transformed with a MinMaxScaler.\n",
    "- Since StudyTimeWeekly and Absences are more similar to uniform distribution than to a normal one, I will use the MinMaxScaler for both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will convert GradeClass through OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'student-performance'\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = [experiment.experiment_id for experiment in mlflow.search_experiments() \n",
    "                 if experiment.name == 'student-performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "minmax_cols = ['ParentalEducation', 'StudyTimeWeekly',\n",
    "                'Absences', 'ParentalSupport']\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "x_sc_train = sc.fit_transform(X_train.loc[:, minmax_cols])\n",
    "X_train.loc[:, minmax_cols] = x_sc_train\n",
    "\n",
    "x_sc_val = sc.transform(X_val.loc[:, minmax_cols])\n",
    "X_val.loc[:, minmax_cols] = x_sc_val\n",
    "\n",
    "x_sc_test = sc.transform(X_test.loc[:, minmax_cols])\n",
    "X_test.loc[:, minmax_cols] = x_sc_test\n",
    "    \n",
    "with open('minmax_scaler.bin', 'wb') as f_out:\n",
    "    pickle.dump(sc, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need for now this transformation due to the models we are going to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_train = ohe.fit_transform(y_train)\n",
    "y_val = ohe.transform(y_val)\n",
    "y_test = ohe.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StudyTimeWeekly.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Absences.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['ParentalEducation', 'Tutoring', 'ParentalSupport',\n",
    "                'Extracurricular', 'Sports', 'Music', 'Volunteering']\n",
    "\n",
    "\n",
    "for col in cat_columns: \n",
    "    data[[col]].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.ParentalEducation.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['StudentID', 'Age', 'Gender', 'Ethnicity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "X_val.drop(columns_to_drop, axis=1, inplace=True)\n",
    "X_test.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dists = [{\n",
    "    'clf': [SVC()],\n",
    "    'clf__C': stats.loguniform(1e-2, 1e3)\n",
    "},\n",
    "{\n",
    "    'clf': [DecisionTreeClassifier()],\n",
    "    'clf__criterion': ['gini','entropy'],\n",
    "    'clf__splitter': ['best','random'],\n",
    "    'clf__class_weight':['balanced', None]\n",
    "},\n",
    "{\n",
    "    \"clf\": [SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)],\n",
    "    \"clf__average\": [True, False],\n",
    "    \"clf__l1_ratio\": stats.uniform(0, 1),\n",
    "    \"clf__alpha\": stats.loguniform(1e-2, 1e0),\n",
    "}, \n",
    "{'clf': [RandomForestClassifier()],\n",
    " 'clf__bootstrap': [True, False],\n",
    " 'clf__max_depth': [10, 20, 30, None],\n",
    " 'clf__min_samples_leaf': [1, 2, 4],\n",
    " 'clf__min_samples_split': [2, 5, 10],\n",
    " 'clf__n_estimators': stats.randint(20, 100)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_search = 10\n",
    "n_cv = 5\n",
    "\n",
    "results = {}\n",
    "\n",
    "for param_dist in param_dists:\n",
    "    print(\"-------------- \" + str(param_dist) + \" --------------\")\n",
    "    clf = param_dist['clf'][0]\n",
    "    \n",
    "    param_dist.pop('clf')\n",
    "    steps = [('clf', clf)]\n",
    "    random_search = RandomizedSearchCV(\n",
    "        Pipeline(steps), param_distributions=param_dist,\n",
    "          cv=n_cv, n_iter=n_iter_search, scoring='f1_macro'\n",
    "    )\n",
    "    random_search.fit(X_train, y_train.values.ravel())\n",
    "    train_score = random_search.best_score_\n",
    "    val_score = random_search.score(X_val, y_val.values.ravel())\n",
    "    estimator_name = random_search.best_estimator_.steps[0][1].__class__\n",
    "    results[estimator_name] = {'estimator': random_search.best_estimator_,\n",
    "                               'mean_train_score': train_score, 'val_score': val_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score , f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    " \n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment('student-performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.lognormal('SVM_C', 0, 1.0)\n",
    "    },\n",
    "    {\n",
    "        'type': 'rf',\n",
    "        'max_depth': hp.randint('rf_max_depth', 5, 100),\n",
    "        'criterion': hp.choice('rf_criterion', ['gini', 'entropy'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'dt',\n",
    "        'criterion': hp.choice('dt_criterion', ['gini','entropy']),\n",
    "        'splitter': hp.choice('dt_splitter', ['best','random']),\n",
    "        'class_weight':hp.choice('dt_class_weight', ['balanced', None])\n",
    "    },\n",
    "    {\n",
    "        'type': 'xgb',\n",
    "        'learning_rate': hp.choice('xgb_learning_rate', [0.0005,0.001, 0.01, 0.5, 1]),\n",
    "        'max_depth' : hp.choice('xgb_max_depth', range(3,21,3)),\n",
    "        'gamma' : hp.choice('xgb_gamma', [i/10.0 for i in range(0,5)]),\n",
    "        'colsample_bytree' : hp.choice('xgb_colsample_bytree', [i/10.0 for i in range(3,10)]),     \n",
    "        'reg_alpha' : hp.choice('xgb_reg_alpha', [1e-5, 1e-2, 0.1, 1, 10, 100]), \n",
    "        'reg_lambda' : hp.choice('xgb_reg_lambda', [1e-5, 1e-2, 0.1, 1, 10, 100]),\n",
    "        'seed': hp.choice('xgb_seed', [0,7,42])\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective (params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        print(params)\n",
    "        classifier_type = params['type']\n",
    "        mlflow.set_tag(\"model\", classifier_type)\n",
    "        del params['type']\n",
    "        if classifier_type == 'svm':\n",
    "            clf = SVC(**params)\n",
    "        elif classifier_type == 'rf':\n",
    "            clf = RandomForestClassifier(**params)\n",
    "        elif classifier_type == 'dt':\n",
    "            clf = DecisionTreeClassifier(**params)\n",
    "        elif classifier_type == 'xgb':\n",
    "            clf = XGBClassifier(**params)\n",
    "        else:\n",
    "            return 0\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        f1 = f1_score(y_val, y_pred,  average='macro')\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        if getattr(clf, 'predict_proba', None):\n",
    "            y_pred_proba = clf.predict_proba(X_val)\n",
    "            roc_auc = roc_auc_score(y_val, y_pred_proba, average='micro', multi_class='ovr')\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=clf,\n",
    "            artifact_path=\"mlruns\"\n",
    "        )\n",
    "        mlflow.log_artifact(local_path=\"minmax_scaler.bin\", artifact_path=\"minmax_scaler\")\n",
    "\n",
    "    return {'loss': -f1, 'status': STATUS_OK } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=tpe.suggest\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    best_result = fmin(\n",
    "      fn=objective, \n",
    "      space=search_space,\n",
    "      algo=algo,\n",
    "      max_evals=32,\n",
    "      trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "\n",
    "print(hyperopt.space_eval(search_space, best_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:5000\")\n",
    "run = client.search_runs(\n",
    "  experiment_ids=experiment_id,\n",
    "  run_view_type=ViewType.ACTIVE_ONLY,\n",
    "  order_by=[\"metrics.accuracy DESC\"]\n",
    ")[0]\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = run.info.run_id\n",
    "\n",
    "mlflow.register_model(\n",
    "    model_uri=f\"runs:/{run_id}/models\",\n",
    "    name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "model_src = RunsArtifactRepository.get_underlying_uri(model_uri)\n",
    "filter_string = \"run_id='{}'\".format(run_id)\n",
    "results = client.search_model_versions(filter_string)\n",
    "model_version = results[0].version\n",
    "model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stage = \"Production\"\n",
    "client.transition_model_version_stage(\n",
    "    name=experiment_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
