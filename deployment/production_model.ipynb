{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pickle\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "EXPERIMENT_NAME = os.getenv(\"EXPERIMENT_NAME\")\n",
    "RUN_ID = os.getenv(\"RUN_ID\")\n",
    "ARTIFACT_FOLDER = os.getenv(\"ARTIFACT_FOLDER\")\n",
    "MODEL_FOLDER = os.getenv(\"MODEL_FOLDER\")\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "experiment_id = [experiment.experiment_id for experiment in mlflow.search_experiments()\n",
    "                 if experiment.name == EXPERIMENT_NAME][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 9/9 [00:02<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "artefacts_uri = f's3://{BUCKET_NAME}/{experiment_id}/{RUN_ID}/artifacts'\n",
    "\n",
    "model_uri = f'{artefacts_uri}/{MODEL_FOLDER}'\n",
    "model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "client.download_artifacts(run_id=RUN_ID, path=ARTIFACT_FOLDER, dst_path='.')\n",
    "\n",
    "with open(f\"{ARTIFACT_FOLDER}/minmax_scaler.bin\", \"rb\") as f_in:\n",
    "    scaler = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scaler_and_model():\n",
    "\n",
    "    BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "    EXPERIMENT_NAME = os.getenv(\"EXPERIMENT_NAME\")\n",
    "    RUN_ID = os.getenv(\"RUN_ID\")\n",
    "    ARTIFACT_FOLDER = os.getenv(\"ARTIFACT_FOLDER\")\n",
    "    MODEL_FOLDER = os.getenv(\"MODEL_FOLDER\")\n",
    "    MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    experiment_id = [experiment.experiment_id for experiment in mlflow.search_experiments()\n",
    "                    if experiment.name == EXPERIMENT_NAME][0]\n",
    "    \n",
    "    artefacts_uri = f's3://{BUCKET_NAME}/{experiment_id}/{RUN_ID}/artifacts'\n",
    "\n",
    "    model_uri = f'{artefacts_uri}/{MODEL_FOLDER}'\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "    client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "    client.download_artifacts(run_id=RUN_ID, path=ARTIFACT_FOLDER, dst_path='.')\n",
    "\n",
    "    with open(f\"{ARTIFACT_FOLDER}/minmax_scaler.bin\", \"rb\") as f_in:\n",
    "        scaler = pickle.load(f_in)\n",
    "\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(scaler, raw_data: pd.DataFrame):\n",
    "    new_data = raw_data.copy()\n",
    "    minmax_cols = ['ParentalEducation', 'StudyTimeWeekly',\n",
    "                   'Absences', 'ParentalSupport']\n",
    "    x_sc = scaler.transform(raw_data.loc[:, minmax_cols])\n",
    "    new_data.loc[:, minmax_cols] = x_sc\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, scaler, raw_data):\n",
    "    df_data = pd.DataFrame(raw_data)\n",
    "    features = preprocessing(scaler, df_data)\n",
    "    pred = model.predict(features)\n",
    "    return float(pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = [{'StudentID': 2566.0,\n",
    " 'Age': 17.0,\n",
    " 'Gender': 0.0,\n",
    " 'Ethnicity': 0.0,\n",
    " 'ParentalEducation': 0.5,\n",
    " 'StudyTimeWeekly': 0.41918744404386094,\n",
    " 'Absences': 0.3103448275862069,\n",
    " 'Tutoring': 0.0,\n",
    " 'ParentalSupport': 0.75,\n",
    " 'Extracurricular': 0.0,\n",
    " 'Sports': 0.0,\n",
    " 'Music': 0.0,\n",
    " 'Volunteering': 0.0}]\n",
    "\n",
    "predict(model, scaler, raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event, context):\n",
    "    \n",
    "    predictions_events = []\n",
    "    \n",
    "    for record in event['Records']:\n",
    "        encoded_data = record['kinesis']['data']\n",
    "        decoded_data = base64.b64decode(encoded_data).decode('utf-8')\n",
    "        ride_event = json.loads(decoded_data)\n",
    "\n",
    "        # print(ride_event)\n",
    "        ride = ride_event['ride']\n",
    "        ride_id = ride_event['ride_id']\n",
    "    \n",
    "        features = prepare_features(ride)\n",
    "        prediction = predict(features)\n",
    "    \n",
    "        prediction_event = {\n",
    "            'model': 'ride_duration_prediction_model',\n",
    "            'version': '123',\n",
    "            'prediction': {\n",
    "                'ride_duration': prediction,\n",
    "                'ride_id': ride_id   \n",
    "            }\n",
    "        }\n",
    "\n",
    "        if not TEST_RUN:\n",
    "            kinesis_client.put_record(\n",
    "                StreamName=PREDICTIONS_STREAM_NAME,\n",
    "                Data=json.dumps(prediction_event),\n",
    "                PartitionKey=str(ride_id)\n",
    "            )\n",
    "        \n",
    "        predictions_events.append(prediction_event)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions_events\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
